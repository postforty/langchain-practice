{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13aecd68",
   "metadata": {},
   "source": [
    "### Short-term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c70d7b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b235313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi! My name is Bob.', additional_kwargs={}, response_metadata={}, id='efdc3c67-5311-41d6-ab8b-a7c1150314d3'),\n",
       "  AIMessage(content=\"Hi Bob! It's nice to meet you. How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--00552fea-f46f-4352-a0ab-5525aec9171e-0', usage_metadata={'input_tokens': 8, 'output_tokens': 18, 'total_tokens': 26, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver  \n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash-lite\",\n",
    "    # [get_user_info],\n",
    "    # checkpointer=InMemorySaver(),  \n",
    ")\n",
    "\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Hi! My name is Bob.\"}]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdfb367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='내 이름이 뭐였지?', additional_kwargs={}, response_metadata={}, id='602eeb32-4b25-4022-bcc4-eb17c16ce8d5'),\n",
       "  AIMessage(content='죄송합니다. 저는 대화 기록을 저장하지 않기 때문에 이전에 제가 당신의 이름을 알았는지, 혹은 당신의 이름이 무엇인지 알 수 없습니다.\\n\\n혹시 다시 알려주시겠어요?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--90757089-5c1f-4ae7-9fdb-c52c7f7dc211-0', usage_metadata={'input_tokens': 8, 'output_tokens': 44, 'total_tokens': 52, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"내 이름이 뭐였지?\"}]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b412e",
   "metadata": {},
   "source": [
    "에이전트에 단기 메모리(스레드 수준 지속성)를 추가하려면 에이전트를 생성할 때 checkpointer 지정해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "322ca809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi! My name is Bob.', additional_kwargs={}, response_metadata={}, id='b08bcb81-5bb0-4ac4-871f-62add6192b3b'),\n",
       "  AIMessage(content=\"Hi Bob! It's nice to meet you. I'm a large language model, trained by Google. How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--dd0bebcb-aa4a-4201-b530-3f74f718486b-0', usage_metadata={'input_tokens': 8, 'output_tokens': 30, 'total_tokens': 38, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver  \n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash-lite\",\n",
    "    # [get_user_info],\n",
    "    checkpointer=InMemorySaver(),  \n",
    ")\n",
    "\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Hi! My name is Bob.\"}]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f9f89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi! My name is Bob.', additional_kwargs={}, response_metadata={}, id='b08bcb81-5bb0-4ac4-871f-62add6192b3b'),\n",
       "  AIMessage(content=\"Hi Bob! It's nice to meet you. I'm a large language model, trained by Google. How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--dd0bebcb-aa4a-4201-b530-3f74f718486b-0', usage_metadata={'input_tokens': 8, 'output_tokens': 30, 'total_tokens': 38, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content='내 이름이 뭐였지?', additional_kwargs={}, response_metadata={}, id='1206530c-93e0-4904-ae86-24247e84258f'),\n",
       "  AIMessage(content='당신의 이름은 Bob이었습니다.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--456539fd-f9f2-409f-836b-4b881a12f763-0', usage_metadata={'input_tokens': 47, 'output_tokens': 8, 'total_tokens': 55, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"내 이름이 뭐였지?\"}]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1525c6",
   "metadata": {},
   "source": [
    "기본적으로 에이전트는 AgentState 사용하여 단기 메모리, 특히 messages 키를 통한 대화 기록을 관리합니다.\n",
    "\n",
    "AgentState 확장하여 필드를 추가할 수 있습니다. \n",
    "\n",
    "사용자 지정 상태 스키마는 state_schema 매개변수를 사용하여 create_agent 에 전달됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d5c5a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent, AgentState\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "\n",
    "class CustomAgentState(AgentState):  \n",
    "    user_id: str\n",
    "    preferences: dict\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash-lite\",\n",
    "    # [get_user_info],\n",
    "    state_schema=CustomAgentState,  \n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "# Custom state can be passed in invoke\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "        \"user_id\": \"user_123\",  \n",
    "        \"preferences\": {\"theme\": \"dark\"}  \n",
    "    },\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70ce7d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hello', additional_kwargs={}, response_metadata={}, id='d1679f9e-4278-44ec-a4ac-6bf2d4a9b4b9'),\n",
       "  AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--2c0626e9-0948-4319-b9f1-3a0d974445bd-0', usage_metadata={'input_tokens': 2, 'output_tokens': 9, 'total_tokens': 11, 'input_token_details': {'cache_read': 0}})],\n",
       " 'user_id': 'user_123',\n",
       " 'preferences': {'theme': 'dark'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b5b139",
   "metadata": {},
   "source": [
    "#### Trim messages  메시지 트리밍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0801e54",
   "metadata": {},
   "source": [
    "@before_model 미들웨어 데코레이터 사용한 메시지 기록 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffb8415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n================================== Ai Message ==================================\\n\\nYour name is Bob. You told me that earlier.\\nIf you'd like me to call you a nickname or use a different name, just say the word.\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import before_model\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "@before_model\n",
    "def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        return None  # No changes needed\n",
    "\n",
    "    first_msg = messages[0]\n",
    "    # first_msg = \"\"\n",
    "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
    "    # recent_messages = messages[-1:] if len(messages) % 2 == 0 else messages[-2:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash-lite\",\n",
    "    # tools=tools,\n",
    "    middleware=[trim_messages],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n",
    "agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "\n",
    "# final_response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a841754f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi, my name is bob', additional_kwargs={}, response_metadata={}, id='edeb9ec8-8b61-4f31-ab73-3031b16b6c58'),\n",
       " AIMessage(content='A furry shadow, soft and sleek,\\nWith eyes of emerald, secrets they speak.\\nA gentle purr, a rumbling sound,\\nOn silent paws, they softly bound.\\n\\nA playful leap, a twitching tail,\\nThrough sunbeams they gracefully trail.\\nThey nap and dream, then stretch and yawn,\\nMasters of comfort, from dusk till dawn.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--faa8a12c-5590-4de7-81d8-f5036d06ee15-0', usage_metadata={'input_tokens': 34, 'output_tokens': 77, 'total_tokens': 111, 'input_token_details': {'cache_read': 0}}),\n",
       " HumanMessage(content='now do the same but for dogs', additional_kwargs={}, response_metadata={}, id='a1bd48fc-ddeb-44f1-bc43-86fe3deb5dc1'),\n",
       " AIMessage(content='A wagging tail, a happy bark,\\nA loyal friend, a shining spark.\\nWith floppy ears and soulful eyes,\\nThey greet the world with sweet surprise.\\n\\nA playful romp, a joyful chase,\\nWith muddy paws and slobbery face.\\nThey guard our homes with loving might,\\nOur furry shadows, pure delight.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--0a5d85fa-153d-4484-bc0c-801ae4e4d3ae-0', usage_metadata={'input_tokens': 120, 'output_tokens': 70, 'total_tokens': 190, 'input_token_details': {'cache_read': 0}}),\n",
       " HumanMessage(content=\"what's my name?\", additional_kwargs={}, response_metadata={}, id='fb54d055-fcd3-45ed-ab44-664d081574aa'),\n",
       " AIMessage(content='You told me your name is Bob!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--2dd63d65-a1a3-43c8-bb05-f730b3c231fd-0', usage_metadata={'input_tokens': 171, 'output_tokens': 8, 'total_tokens': 179, 'input_token_details': {'cache_read': 0}})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_response[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4a94d3",
   "metadata": {},
   "source": [
    "#### Delete messages  메시지 삭제\n",
    "\n",
    "그래프 상태에서 메시지를 삭제하여 메시지 기록을 관리할 수 있습니다.\n",
    "\n",
    "이 기능은 특정 메시지를 제거하거나 전체 메시지 기록을 지우려는 경우에 유용합니다.\n",
    "\n",
    "그래프 상태에서 메시지를 삭제하려면 RemoveMessage 를 사용하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f01aff8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('human', \"hi! I'm bob\")]\n",
      "[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob.')]\n",
      "[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob.'), ('human', \"what's my name?\")]\n",
      "[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob.'), ('human', \"what's my name?\"), ('ai', 'Your name is Bob.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import after_model\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash-lite\",\n",
    "    tools=[],\n",
    "    system_prompt=\"Please be concise and to the point.\",\n",
    "    # middleware=[delete_old_messages], # * 사용하지 않은 경우\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"hi! I'm bob\"}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    print([(message.type, message.content) for message in event[\"messages\"]])\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    print([(message.type, message.content) for message in event[\"messages\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7b7d022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}, id='998e138c-1596-4f38-8f5c-fcc16fe8faaf'),\n",
       "  AIMessage(content='Hi Bob.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--f8297a9e-6ea4-470b-8065-b893ac1bbcac-0', usage_metadata={'input_tokens': 15, 'output_tokens': 3, 'total_tokens': 18, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content=\"what's my name?\", additional_kwargs={}, response_metadata={}, id='8b0a216e-fb30-4b6e-baae-91ba1bc09d85'),\n",
       "  AIMessage(content='Your name is Bob.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--04785f00-c95e-48b8-846e-05e3fd4dae5a-0', usage_metadata={'input_tokens': 26, 'output_tokens': 5, 'total_tokens': 31, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content=\"what's my name?\", additional_kwargs={}, response_metadata={}, id='d6d072c7-f16a-4105-a900-3c9cd407d888'),\n",
       "  AIMessage(content='Your name is Bob.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--a7b2f8d9-2056-4a2f-b47b-7bf7752e76c8-0', usage_metadata={'input_tokens': 39, 'output_tokens': 5, 'total_tokens': 44, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n",
    "    config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3d73131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('human', \"hi! I'm bob\")]\n",
      "[('human', \"hi! I'm bob\"), ('ai', 'Hello Bob.')]\n"
     ]
    }
   ],
   "source": [
    "@after_model\n",
    "def delete_old_messages(state: AgentState, runtime: Runtime) -> dict | None:\n",
    "    \"\"\"Remove old messages to keep conversation manageable.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    if len(messages) > 2:\n",
    "        # remove the earliest two messages\n",
    "        return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:2]]}\n",
    "        # 모든 메시지 제거\n",
    "        # return {\"messages\": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]}\n",
    "    \n",
    "    return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash-lite\",\n",
    "    tools=[],\n",
    "    system_prompt=\"Please be concise and to the point.\",\n",
    "    middleware=[delete_old_messages], # * 사용한 경우\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"hi! I'm bob\"}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    print([(message.type, message.content) for message in event[\"messages\"]])\n",
    "\n",
    "# for event in agent.stream(\n",
    "#     {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n",
    "#     config,\n",
    "#     stream_mode=\"values\",\n",
    "# ):\n",
    "#     print([(message.type, message.content) for message in event[\"messages\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "583bd6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's my name?\", additional_kwargs={}, response_metadata={}, id='35ae81d9-67b2-4df1-bf84-03ee3d6f0b3a'),\n",
       "  AIMessage(content='Your name is Bob.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--e78bd44f-c1ce-4a1f-8f06-8c47e9ba91b4-0', usage_metadata={'input_tokens': 26, 'output_tokens': 5, 'total_tokens': 31, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n",
    "    config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b73f07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's my name?\", additional_kwargs={}, response_metadata={}, id='dd8264b0-272e-4a33-9b26-da734d73753a'),\n",
       "  AIMessage(content='I do not have access to your personal information, including your name.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--ccff5630-bf10-40e6-bc32-8243f379916f-0', usage_metadata={'input_tokens': 28, 'output_tokens': 14, 'total_tokens': 42, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n",
    "    config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481bf941",
   "metadata": {},
   "source": [
    "#### Summarize messages  메시지 요약\n",
    "\n",
    "채팅 모델을 사용하여 메시지 기록을 요약할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bd95c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Bob!\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash\",\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=\"google_genai:gemini-2.5-flash-lite\",\n",
    "            # max_tokens_before_summary=4000,  # Trigger summarization at 4000 tokens\n",
    "            max_tokens_before_summary=300,  # Trigger summarization at 300 tokens\n",
    "            messages_to_keep=20,  # Keep last 20 messages after summary\n",
    "        )\n",
    "    ],\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n",
    "agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "\n",
    "final_response[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "short_term_memory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
